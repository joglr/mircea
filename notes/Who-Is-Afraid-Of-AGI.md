# Who Is Afraid of AGI?

*February, 2023*

AGI stands for Artificial General Intelligence. 

It is theoretized to be the level of AI at which an "algorithm" is as intelligent as a human. It is the "phylosopher's stone" of the modern techno-alchemist.

Many people and sometimes smart ones are afraid that once we invent an advanced enough AI, there is only one small step to inventing an AGI - an AI that is as "intelligent" (whatever that may mean) than humans. At that point, there is only one more step to a more-intelligent-than-humans-algorithm. And then, this new "algorithm" will start improving itself... And you can imagine what's next: the techno-apocalypse comes because the super-AGI is now so much more intelligent than humans and will just decide to dispose with our species or make it into it's pets. 

Reportedly, Elon Musk can't sleep at night because of his worries about AI. 

My claim is that those who are afraid of AGI as the next step in the progress of current AI techniques, and of it taking over the world, are *literally afraid of mathematics*. Because the current AI techniques are just advanced mathematics. There is a certain increase in complexity starting from linear regression, to logistic regression, to neural networks, to deep neural networks, and large language models, but after all it's still a admittedly, very complicated mathematical function that we're talking about. 

So being afraid that a mathematical function or a set of functions that represent statistical approximations based on a lot of data will suddently become more intelligent than humans is silly. Being afraid that these functions will eventually take over the world and drive humanity extict is even more silly. 

By being afraid of AI you're being afraid of matehmatics. And remember that it was the not very smart kids who were afraid of mathematics in school. Don't be like them :) 

I've made a visual summary of this idea: 

![](../docs/assets/this_is_jim.png)



## References

- Unlikely to have AGI w/o a sense of self [eliot miranda on linkedin](https://www.linkedin.com/feed/update/urn:li:activity:7022617377229983744/) . And a sense of self does not easily come without a body is my conjecture. 
- Elon musk [can't sleep at night](https://www.geospatialworld.net/blogs/scares-elon-musk-artificial-intelligence/) because he's afraid of AI; Bostrom also wrote [about his fears in a book](https://www.vox.com/future-perfect/2018/11/2/18053418/elon-musk-artificial-intelligence-google-deepmind-openai) - (at least he's capitalizing on his fears)
- What Software Engineering teaches us about AGI - The customer does not know what they want; everybody thinks they know what they talk about at the high-level; when they are faced with details, they realize that it wasn't exactly it; in the context of AGI - nobody thinks much too deeply about the consequences of creating an actual human-like-AI; for a good example is the [short story about MMAcevedo](https://qntm.org/mmacevedo) - a fantastic little gem of SF where SF does what it does best; takes an idea and explores it's implications; in this case it's the idea of uploading one's mind in a computer; sounds nice, right? (see also the [discussion](https://www.reddit.com/r/slatestarcodex/comments/lqr8hu/fiction_mmacevedo_the_brain_image_of_the_first/) about the story on r/slatestarcodex)

## Related Ideas
- we "fly" but not like birds; computers solve problems, but not like humans; 
- you can be afraid of AI, but in a different context: if people who are in "awe" of the technology connect it to dangerous systems. but then, the fear is not of the AI per se, but of the connecting of the dangerous system (car, application evaluation, etc.) to a statistical model that nobody understands exactly the workings of
- Some less excited people, like Gary Marcus and Grady Booch debate whether AGI will happen in our lifetime or maybe not even in the lifetime of our children's children. 