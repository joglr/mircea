AGI stands for Artificial General Intelligence. 
It is theoretized to be the level of AI at which an "algorithm" is more as intelligent as a human. 

The Sillycon Valley technobros are afraid that once we invent AGI there is only one small step to inventing something that is "even more intelligent than humans". At that point, that more intelligent than humans system will start improving itself. And soon after that, the techno-apocalypse comes. With the SuperAGI taking over the world. 

In this essay I will try to explain why those who are afraid of AGI are literally afraid of mathematics. And you're usually not very smart when you're afraid of mathematics. 

// to be continued